{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Программирование для всех\n",
    "\n",
    "*Алла Тамбовцева, НИУ ВШЭ*\n",
    "\n",
    "## Парсинг HTML-файлов с помощью `BeautifulSoup`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы уже немного познакомились со структурой html-страниц, теперь попробуем выгрузить информацию из реально существующей страницы, а точнее, с сайта [nplus1.ru](https://nplus1.ru/). Наша задача – выгрузить недавние новости в датафрейм `pandas`, чтобы потом сохранить все в файл Excel.\n",
    "\n",
    "Для работы нам понадобится модуль `requests` для отправки запросов, для «подключения» к странице и получения ее содержимого в виде строки, и функция `BeautifulSoup` из библиотеки `bs4` для удобного поиска по полученной строке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним ссылку на главную страницу в переменную `main`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = \"https://nplus1.ru/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем запрос, отправим его и получим ответ с помощью функции `get()` из `requests`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(main) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы просто посмотрим на объект, мы ничего особенного не увидим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объект page имеет тип `Response` и скрыт от наших глаз. Однако при его вызове мы видим число 200 – это код результата, который означает, что страница благополучно загружена."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У объекта типа `Response` есть атрибут `.text`, в котором хранится исходный код страницы, который мы можем посмотреть, нажав *Ctrl+U* в Chrome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат выше – это обычная строка, тип string. Выполнять поиск по такой строке неудобно, поэтому преобразуем эту строку в объект типа `BeautifulSoup`, который позволяет выполнять поиск по тегам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы сгрузить все новости с главной страницы сайта, нужно собрать все ссылки на страницы с этими новостями. Ссылки в html-файле всегда заключены в тэг `<a></a>` и имеют атрибут `href`. Найдем кусочки кода HTML, соответствующие всем ссылкам на главной странице сайта:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"hover:underline transition-colors duration-75\" href=\"/search/empty/768\">Генетика</a>,\n",
       " <a class=\"hover:underline transition-colors duration-75\" href=\"/search/empty/890\">Математика</a>,\n",
       " <a class=\"hover:underline transition-colors duration-75\" href=\"/search/empty/871\">Космонавтика</a>,\n",
       " <a class=\"hover:underline transition-colors duration-75\" href=\"/search/empty/876\">Археология</a>,\n",
       " <a class=\"hover:underline transition-colors duration-75\" href=\"/search/empty/775\">Нейронауки</a>,\n",
       " <a class=\"hover:underline transition-colors duration-75\" href=\"/search/empty/767\">На мышах</a>,\n",
       " <a class=\"hover:underline transition-colors duration-75\" href=\"/search/empty/771\">Звук</a>,\n",
       " <a class=\"hover:underline transition-colors duration-75\" href=\"/search/empty/772\">Красота</a>,\n",
       " <a class=\"hover:underline transition-colors duration-75\" href=\"/search/empty/778\">Научные закрытия</a>,\n",
       " <a class=\"hover:underline transition-colors duration-75\" href=\"/search/empty/917\">ИИ спешит на помощь</a>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_raw = soup.find_all(\"a\") \n",
    "links_raw[10:20]  # несколько штук для примера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В коде выше мы использовали метод `.find_all()`, который выполняет поиск по заданному тэгу и возвращает список частей кода HTML с выбранным тэгом. Каждый элемент возвращаемого списка имеет тип `BeautifulSoup` и структуру, очень похожую на словарь. Например, ссылка `<a class=\"hover:underline transition-colors duration-75\" href=\"/search/empty/768\">Генетика</a>` изнутри выглядит как словарь следующего вида:\n",
    "\n",
    "    {'href' : '/search/empty/768', \n",
    "     'class' : 'hover:underline transition-colors duration-75'}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы помним, значение по ключу из словаря можно вызвать с помощью метода `.get()`. Давайте извлечем значения по ключу `href` из каждого элемента списка `links`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/search/empty/768',\n",
       " '/search/empty/890',\n",
       " '/search/empty/871',\n",
       " '/search/empty/876',\n",
       " '/search/empty/775',\n",
       " '/search/empty/767',\n",
       " '/search/empty/771',\n",
       " '/search/empty/772',\n",
       " '/search/empty/778',\n",
       " '/search/empty/917']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = [li.get(\"href\") for li in links_raw] \n",
    "links[10:20]  # несколько штук для примера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылок в списке выше много. Но нам нужны только новости – ссылки, которые начинаются с `https://nplus1.ru/news`. Создадим пустой список `news` и будем добавлять в него только ссылки, которые удовлетворяют этому условию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "for li in links:\n",
    "    if \"https://nplus1.ru/news/\" in li:\n",
    "        news.append(li) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая ссылка ведет не совсем на новость, скорее, на объявление, поэтому давайте ее уберем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = news[1:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь наша задача сводится к следующему: изучить одну страницу с новостью, научиться из нее вытаскивать текст и всю необходимую информацию, а потом применить весь набор действий к каждой ссылке из `news` в цикле. Посмотрим на новость с индексом 0, у вас может быть другая, новости обновляются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "link0 = news[0]\n",
    "print(link0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отправим запрос к этой странице с одной новостью и обработаем исходный код страницы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page0 = requests.get(link0)\n",
    "soup0 = BeautifulSoup(page0.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем найти заголовок новости. Изучив исходный код страницы, заметим, что он находится в разных местах страницы. Возьмем самый простой вариант – тэг `<title>`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find() вместо find_all(), так как результат точно будет один\n",
    "# незачем писать soup0.find_all(\"title\")[0] для извлечения единственного элемента списка,\n",
    "# если можно сразу вернуть этот единственный элемент\n",
    "\n",
    "soup0.find(\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлечем текст, который заключен внутри тэгов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Четвероногого робота научили стоять на воротах'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = soup0.find(\"title\").text\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем теперь имя автора. Заметим, что оно находится в тэге `<meta>`, причем не просто в `<meta>`, а с атрибутом `name`, равным `mediator_author`. Чтобы учесть это уточнение в поиске, подадим на вход `.find()` словарь с названием атрибута и его значением:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<meta content=\"Григорий Копиев\" name=\"mediator_author\"/>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup0.find(\"meta\", {\"name\" : \"mediator_author\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось извлечь имя автора из `content` по аналогии с тем, как мы ранее извлекали ссылку из `href`. Используем метод `.get()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author = soup0.find(\"meta\", {\"name\" : \"mediator_author\"}).get(\"content\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичным образом извлечем дату публикации новости:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = soup0.find(\"meta\", {\"itemprop\" : \"datePublished\"}).get(\"content\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С остальными характеристиками – сложностью и рубриками – все более интересно. С одной стороны, их можно найти точно так же по тэгам и атрибутам, но для надежности (не все названия атрибутов здесь понятны и гарантируют уникальность) давайте сузим пространство для поиска и будем искать их не по всей странице, а в пределах какого-нибудь раздела. Такой раздел есть, он имеет очень длинное значение атрибута `class`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"flex flex-wrap lg:mb-10 gap-2 text-tags xl:pr-9\">\n",
       "<span class=\"relative before:block before:w-px before:bg-current before:h-4 before:absolute before:left-0 group pl-2 flex inline-flex items-center\">\n",
       "<span class=\"group-hover:text-main transition-colors duration-75\">16:04</span>\n",
       "</span>\n",
       "<a class=\"relative before:block before:w-px before:bg-current before:h-4 before:absolute before:left-0 group pl-2 flex inline-flex items-center\" href=\"/news/2022/10/17\">\n",
       "<span class=\"group-hover:text-main transition-colors duration-75\">17.10.22</span>\n",
       "</a>\n",
       "<a class=\"relative before:block before:w-px before:bg-current before:h-4 before:absolute before:left-0 group pl-2 flex inline-flex items-center\" href=\"/material/difficulty/2\">\n",
       "<svg class=\"w-4 h-4 mr-1 group-hover:text-main transition-colors duration-75 stroke-current\">\n",
       "<use xlink:href=\"#n1_star\"></use>\n",
       "</svg>\n",
       "<span class=\"group-hover:text-main transition-colors duration-75\">2.4</span>\n",
       "</a>\n",
       "<a class=\"relative before:block before:w-px before:bg-current before:h-4 before:absolute before:left-0 group pl-2 flex inline-flex items-center\" href=\"/search/empty/883\">\n",
       "<span class=\"group-hover:text-main transition-colors duration-75\">Роботы и дроны</span>\n",
       "</a>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div = soup0.find(\"div\",\n",
    "                 {\"class\" : \"flex flex-wrap lg:mb-10 gap-2 text-tags xl:pr-9\"})\n",
    "div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе встречаются более мелкие части с тэгами `span`, в которых хранится дата, сложность статьи и рубрики. К сожалению, сайт сейчас в процессе перехода к новой структуре и новому дизайну, поэтому не всегда последовательность элементов будет такой (где-то будет вклиниваться время публикации статьи), но каким-то быстрым способом мы с этой проблемой сейчас не справимся. Поэтому отберем элементы как есть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffc = div.find_all(\"span\")[1]\n",
    "rubs_raw = div.find_all(\"span\")[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diffc)\n",
    "print(rubs_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте извлечем из блоков кода HTML с рубриками текст с названиями рубрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17.10.22', '2.4', 'Роботы и дроны']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubs = [r.text for r in rubs_raw]\n",
    "rubs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Склеим их в одну строку по запятой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubs_text = \", \".join(rubs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось аналогичным образом сохранить самое главное – текст новости. Заметим, что его нужно собирать по абзацам – по тэгам `<p>` с атрибутом `class`, равным `mb-6`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"text-36 md:text-44 xl:text-54 font-spectral text-main-gray mb-6\">Его научили трем движениям для успешного перехвата</p>,\n",
       " <p class=\"mb-6\">Американские инженеры научили четвероногого робота работать футбольным вратарем. Он анализирует траекторию полета мяча после удара и прыгает, чтобы перехватить его и не дать попасть в ворота. Статья о разработке <a href=\"https://arxiv.org/abs/2210.04435\" rel=\"noreferrer noopener\" target=\"_blank\">опубликована</a> на arXiv.org.</p>,\n",
       " <p class=\"mb-6\">Как правило, инженеры-робототехники решают прикладные задачи, которые можно напрямую применить на практике. Например, это создание эффективных алгоритмов и приспособлений для перемещения ходячих роботов по пересеченной местности. Но есть и немало работ, в которых инженеры, казалось бы, занимаются не особо полезными вещами, к примеру, <a href=\"https://nplus1.ru/news/2019/11/19/cassie-juggling\" rel=\"noreferrer noopener\" target=\"_blank\">обучением</a> двуногого робота чеканке мячика. Однако в процессе решения одной конкретной задачи они создают более фундаментальные наработки, которые в перспективе можно применить для многих практических применений. Так, в той же работе по чеканке мяча разработчики создали алгоритм, позволяющий роботу одновременно выполнять две динамические задачи.</p>,\n",
       " <p class=\"mb-6\">В новой работе та же группа инженеров из лаборатории гибридной робототехнике Университета Калифорнии в Беркли во главе с Кушилем Сринатом (Koushil Sreenath) снова научила робота работать с мячом, но на этот раз инженеры использовали четвероногого Mini Cheetah и сделали его футбольным вратарем.</p>,\n",
       " <p class=\"mb-6\">Разработчики научили робота трем основным движениям: сдвигу в сторону, прыжку и нырку. Под последним движением авторы подразумевают прыжок в сторону и последующее падение, чтобы перехватить мяч, летящий в нижний, а не верхний угол ворот.</p>,\n",
       " <p class=\"mb-6\">При ударе робот определяет положение мяча с помощью камеры глубины, а затем планировщик определяет подходящее движение. После этого алгоритм подбирает траекторию частей робота, позволяющую перехватить мяч, а затем низкоуровневый контроллер вычисляет соответствующие крутящие моменты для моторов, позволяющие реализовать эту траекторию.</p>,\n",
       " <p class=\"mb-6\">Инженеры сначала обучили в симуляции с помощью платформы <a href=\"https://github.com/NVIDIA-Omniverse/IsaacGymEnvs\" rel=\"noreferrer noopener\" target=\"_blank\">Isaac Gym</a>, реализующей обучение с подкреплением в виртуальном пространстве, имитирующим физические взаимодейтствия. После этого выученные навыки успешно перенесли на реального робота и продемонстрировали вратарские способности на видео. В большинстве случаев робот тратит на движения 0,9 секунды.</p>,\n",
       " <p class=\"mb-6\">В прошлом году мы <a href=\"https://nplus1.ru/news/2021/07/06/mini-cheetah-jumping\" rel=\"noreferrer noopener\" target=\"_blank\">рассказывали</a> о том, как эта группа инженеров научила Mini Cheetah перепрыгивать препятствия.</p>,\n",
       " <p class=\"mb-6\">Wing показала новые грузовые дроны для доставки товаров и продуктов. Компания разработала несколько аппаратов под посылки разной массы: от 250 грамм до трех килограмм.</p>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pars_raw = soup0.find_all(\"p\", {\"class\" : \"mb-6\"}) \n",
    "pars_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлечем текст в чистом виде из каждого элемента списка `pars_raw`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = [p.text for p in pars_raw] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Склеим полученные строки в одну большую строку через `.join()`, а заодно избавимся от посторонних символов `\\xa0`, которые соответствуют неразрывным пробелам, и `\\n`, которые соответствуют переходам на новую строку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(pars)\n",
    "text = text.replace(\"\\xa0\", \" \") \n",
    "text = text.replace(\"\\n\", \" \") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь все красиво. Напишем функцию для выгрузки информации по одной новости и применим ее к новостям на главной странице."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(link0):\n",
    "    page0 = requests.get(link0)\n",
    "    soup0 = BeautifulSoup(page0.text) \n",
    "    title = soup0.find(\"title\").text\n",
    "    author = soup0.find(\"meta\", {\"name\" : \"mediator_author\"}).get(\"content\") \n",
    "    date = soup0.find(\"meta\", {\"itemprop\" : \"datePublished\"}).get(\"content\") \n",
    "    div = soup0.find(\"div\",\n",
    "                 {\"class\" : \"flex flex-wrap lg:mb-10 gap-2 text-tags xl:pr-9\"})\n",
    "    diffc = div.find_all(\"span\")[1].text\n",
    "    rubs_raw = div.find_all(\"span\")[2:]\n",
    "    rubs = [r.text for r in rubs_raw]\n",
    "    rubs_text = \", \".join(rubs)\n",
    "    pars_raw = soup0.find_all(\"p\", {\"class\" : \"mb-6\"}) \n",
    "    pars = [p.text for p in pars_raw] \n",
    "    text = \" \".join(pars)\n",
    "    text = text.replace(\"\\xa0\", \" \") \n",
    "    return title, author, date, diffc, rubs_text, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы сайт не понял, что мы его автоматически грабим, будем выгружать новости постепенно – с задержкой в 1.5 секунды. Импортируем для этого функцию `sleep` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь будем применять функцию в цикле к каждой ссылке в `news`, только с одним дополнением – добавленной конструкцией `try-except`, которая позволит продолжать исполнение цикла, если при применении функции Python столкнулся с ошибкой любого вида:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://nplus1.ru/news/2022/10/17/cetveronogogo-robota-naucili-otbivat-myaci\n",
      "https://nplus1.ru/news/2022/10/17/mola-alexandrini\n",
      "https://nplus1.ru/news/2022/10/17/cetveronogogo-robota-naucili-otbivat-myaci\n",
      "https://nplus1.ru/news/2022/10/17/greenland\n",
      "https://nplus1.ru/news/2022/10/17/gold-label\n",
      "https://nplus1.ru/news/2022/10/17/tagar-rock-art\n",
      "https://nplus1.ru/news/2022/10/15/barium\n",
      "https://nplus1.ru/news/2022/10/15/scythians\n",
      "https://nplus1.ru/news/2022/10/15/chinese-coins\n",
      "https://nplus1.ru/news/2022/10/14/anguilla-anguilla\n",
      "https://nplus1.ru/news/2022/10/14/oldest-grave\n",
      "https://nplus1.ru/news/2022/10/14/brain-model-rats\n",
      "https://nplus1.ru/news/2022/10/14/gorn\n",
      "https://nplus1.ru/news/2022/10/14/polyarizuemost-protona\n",
      "https://nplus1.ru/news/2022/10/14/direct-imaging-technology\n",
      "https://nplus1.ru/news/2022/10/14/charge-transfer-photocatalysis\n",
      "https://nplus1.ru/news/2022/10/14/pangur-ban\n",
      "https://nplus1.ru/news/2022/10/14/charles-xii\n",
      "https://nplus1.ru/news/2022/10/13/edmontosaurus-mummy\n",
      "https://nplus1.ru/news/2022/10/13/neanderthals-vs-modern-humans\n",
      "https://nplus1.ru/news/2022/10/13/kakapo\n",
      "https://nplus1.ru/news/2022/10/13/vliyanie-elektronnyx-korrelyacii-v-kristallax-vyyavili-s-attosekundnoi-tocnostyu\n",
      "https://nplus1.ru/news/2022/10/13/rurikovo-gorodishche\n",
      "https://nplus1.ru/news/2022/10/13/tunnug\n",
      "https://nplus1.ru/news/2022/10/12/cell-readr\n",
      "https://nplus1.ru/news/2022/10/12/bolsie-xoxlatye-pingviny\n",
      "https://nplus1.ru/news/2022/10/12/moral-tradeoff-system\n",
      "https://nplus1.ru/news/2022/10/12/smiling-electrons\n",
      "https://nplus1.ru/news/2022/10/12/short-list-2022\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/12/phanagoria\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/12/pheucticus-ludovicianus-piranga-olivacea\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/11/woow-we-now-can-save-earth\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/11/firefly-alpha-yes-or-no\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/11/himera\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/11/calonectris-leucomelas\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/11/photoelectrosynthesis-nitriles\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/11/speckle-correlations\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/11/artezian\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/11/xiaoma-caves\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/10/tardigrades-aged-well\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/10/dinizia-excelsa\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/10/insight-forever\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/10/blinchiki\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/10/econobel\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/10/sanctuary-of-samian-poseidon\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/10/berenike\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/08/cooling-of-levitated-microsphere\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/08/rotational-Doppler-effect\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/03/saka-burial\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/04/cows\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/12/phanagoria\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/11/xiaoma-caves\n",
      "https://nplus1.ru/news/2022/10/12/moral-tradeoff-system\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/11/firefly-alpha-yes-or-no\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/07/fish-traps\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/10/dinizia-excelsa\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/11/woow-we-now-can-save-earth\n",
      "https://nplus1.ru/news/2022/10/14/brain-model-rats\n",
      "https://nplus1.ru/news/2022/10/14/charles-xii\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/10/sanctuary-of-samian-poseidon\n",
      "https://nplus1.ru/news/2022/10/13/neanderthals-vs-modern-humans\n",
      "https://nplus1.ru/news/2022/10/17/mola-alexandrini\n",
      "https://nplus1.ru/news/2022/10/14/anguilla-anguilla\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/12/pheucticus-ludovicianus-piranga-olivacea\n",
      "https://nplus1.ru/news/2022/10/13/kakapo\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/09/30/jewelry-for-brain\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/04/first-stars-or-no\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/05/Standing-PB\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/06/Self-Induced-Larmor-Precession\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/06/pentalayer-graphene-moire-superconductance\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/08/rotational-Doppler-effect\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/08/cooling-of-levitated-microsphere\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/11/speckle-correlations\n",
      "Something went wrong\n",
      "https://nplus1.ru/news/2022/10/11/photoelectrosynthesis-nitriles\n",
      "https://nplus1.ru/news/2022/10/12/smiling-electrons\n",
      "https://nplus1.ru/news/2022/10/13/vliyanie-elektronnyx-korrelyacii-v-kristallax-vyyavili-s-attosekundnoi-tocnostyu\n",
      "https://nplus1.ru/news/2022/10/14/charge-transfer-photocatalysis\n",
      "https://nplus1.ru/news/2022/10/14/polyarizuemost-protona\n"
     ]
    }
   ],
   "source": [
    "info = []\n",
    "for n in news:\n",
    "    # пробуй исполнить следующий код\n",
    "    try:\n",
    "        res = get_news(n)\n",
    "        info.append(res)\n",
    "        print(n)\n",
    "    # если он вызвал ошибку, печатай сообщение и иди дальше\n",
    "    except:\n",
    "        print(\"Something went wrong\")\n",
    "        print(n)\n",
    "    sleep(1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ура! Несмотря на то, что ближе к концу списка со ссылками мы стали получать сообщения об ошибках, новости за последние несколько дней сгрузились корректно (сайт в разработке, пока небольшие проблемы с унификацией и упорядочиванием ссылок).\n",
    "\n",
    "Посмотрим на несколько элементов `info`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Археологи обнаружили древнейшее захоронение на севере Германии',\n",
       "  'Михаил Подрезов',\n",
       "  '2022-10-14',\n",
       "  '2.3',\n",
       "  'Археология, Антропология',\n",
       "  'Ему около 10,5 тысячи лет Археологи провели новые раскопки на осушенном болоте Дювензее и обнаружили древнейшее захоронение на севере Германии. Оно представляет собой кремацию, совершенную, по предварительным оценкам, около 10,5 тысячи лет, то есть в эпоху раннего мезолита. Об этом сообщило Управление археологии федеральной земли Шлезвиг-Гольштейн на своем сайте. На территории современной федеральной земли Шлезвиг-Гольштейн находится осушенное торфяное болото Дювензее, известное благодаря археологическим находкам. Изначально Дювензее представляло собой озеро, образовавшееся на месте отступившего ледника и достигшее максимума своей полноводности в самом начале эпохи голоцена – в раннем пребореальном периоде. Но затем оно постепенно заилилось, превратившись в конечном счете в торфяное болото. Как археологический объект Дювензее стало известно в 1923 году, когда в дренажных канавах обнаружили мезолитические артефакты. Дальнейшие исследования позволили выявить несколько древних стоянок охотников-собирателей-рыболовов. Всего на площади около 4,3 квадратных километра почти за сто лет исследований ученые обнаружили 23 памятника каменного века, 17 из которых (по данным на 2018 год) были раскопаны. Помимо разных типов каменных орудий, археологи нашли на этой территории 9000-летнее деревянное весло, деревянные элементы топора, костяные наконечники и топор из рога, кострища, остатки добычи и прочей пищи (например, многочисленных орехов) Исследователи из Центра балтийской и скандинавской археологии под руководством Харальда Любке (Harald Lübke) провели новые раскопки на осушенном болоте Дювензее. Главным открытием этого сезона стало обнаружение древнейшего на сегодня захоронения, расположенного на севере Германии. Оно представляет собой кремированные останки, принадлежавшие раннемезолитическому охотнику-собирателю-рыболову, жившему около 10500 лет назад, то есть в самом начале эпохи голоцена. Во время работ археологи обнаружили несколько фрагментов костей, некоторые из которых были сильно обуглены. После чего они вырезали всю могилу монолитом, чтобы более детально ее разобрать и исследовать в лабораторных условиях. Отмечается, что в этом регионе захоронения эпохи раннего мезолита встречаются крайне редко. Единственная сопоставимая находка известна с Ютландии, где человека также похоронили по обряду кремации. На севере Германии и юге Скандинавии находки относятся уже к более поздним временам – VII–VI тысячелетиям до нашей эры. Ранее на N + 1 рассказывали об исследованиях материалов из мезолитического могильника, раскопанного в северной части Онежского озера еще в 1936–1938 годах. Так, археологи связали его появление с самым суровым голоценовым похолоданием, которое произошло около 8200 лет назад. Кроме того, исследование костяных подвесок из этих погребений показало, что часть из них была изготовлена из человеческих останков. Археологи исследовали материалы из кургана IV века до нашей эры Археологи исследовали материалы из парного скифского погребения IV века до нашей эры, раскопанного на Украине в кургане у села Булгаково. По всей видимости, в нем находились останки мужчины и женщины, принадлежавших к низшим слоям аристократии. В их погребении сохранились изделия кожи, древесины и ткани, например, обувь, деревянная утварь, а также колчан со стрелами. Кроме того, при умерших находились копье, греческие сосуды, драгоценные украшения и бронзовый котел. Об этом сообщается в статье, опубликованной в Oxford Journal of Archaeology.'),\n",
       " ('Человеческий мини-мозг прижился в мозге крысы и среагировал на прикосновение к усам',\n",
       "  'Полина Гребенкина',\n",
       "  '2022-10-14',\n",
       "  '4.6',\n",
       "  'Биология, Медицина',\n",
       "  'Модели органа, сделанные из клеток человека, прижились и развились в мозге крыс, после чего повлияли на поведение грызунов. Ученые из США придумали, как улучшить создание моделей человеческого мозга. В исследовании, опубликованном в Nature, утверждается, что пересадка мозгового органоида новорожденным крысам позволяет добиться того, что не получалось раньше: искусственный мини-мозг приживается и взаимодействует с другими клетками в организме крысы, в том числе реагирует на внешние раздражители — например, на прикосновение к усам. Поскольку изучать головной мозг и его патологии на человеке сложно, ученые вынуждены использовать для этой цели лабораторных животных — грызунов или даже собак. Проблема в том, что такие модели не отражают все характеристики человеческого мозга и процессы в нем. Поэтому ученые стараются сделать мини-модели головного мозга из стволовых клеток человека — мозговые органоиды. Чтобы сделать структуру, похожую на человеческий мозг, ученые выращивают стволовые клетки в окружении, которое заставляет их становиться клетками мозга. После этого органоид переносят животным, чтобы проверить, как он работает. И вот тут начинаются проблемы. Из-за своего искусственного происхождения мини-мозги не могут нормально развиваться в организме, а значит и функционировать должным образом, взаимодействуя с другими частями мозга грызунов. Ученые стараются решить проблему, создавая новые подходы к созданию и пересадке органоидов. Команда исследователей из Стэнфордского университета под руководством Серджиу Пашка (Sergiu P. Pașca) продвинулась в этом деле. Они перенесли мозговой органоид новорожденным крысам, а не взрослым, как делали их коллеги. В этот период в мозге еще не завершил свое развитие, что позволило органоиду прижиться и встроиться в его структуру. Кроме того, у мышей не было тимуса, а значит их адаптивный иммунитет не смог атаковать трансплантат. Мозговые органоиды не только прижились в мозгу крыс: ученые отметили девятикратное увеличение объема трансплантата через три месяца после операции. Более того, внутри него появились сосуды и клетки микроглии — макрофаги нервной системы. Клетки мозгового органоида, который встроили в организм грызунов, стали отличаться от тех, что выращивали in vitro. Они больше и экспрессируют гены, связанные с созреванием нейронов, а значит — ученые добились развития органоида в живом организме. Кроме того, ученые выяснили, что с помощью мозгового органоида можно влиять на поведение крыс, для чего использовали методы оптогенетики. Сначала исследователи сделали органоид, который экспрессировал светочувствительный канал. Это белок, который открывается под действием света и меняет активность клеток. Затем мозговой органоид перенесли мышам, а через три месяца в трансплантат добавили оптическое волокно, которое генерировало красный или синий свет. Животные получали награду, если пили во время действия синего света. Через пятнадцать дней те крысы, которым вживили мозговой органоид со светочувствительным белком, поняли этот принцип. Ученые сделали вывод, что клетки органоида интегрировались в мозг и стали активировать нейроны, чтобы получать награду. Еще одно доказательство интеграции трансплантата смогли обнаружить, потрогав крыс за усы. В ответ на такой внешний стимул ученые заметили активацию части клеток в мозговом органоиде . С помощью пересадки органоида новорожденным крысам с иммунодефицитом, ученые смогли решить сразу несколько проблем: их мини-мозг прижился, начал развиваться внутри живого организма и активно с ним взаимодействовать.  Исследователи предлагают использовать свою модель не только для изучения нормы. Им удалось сделать мозговые органоиды из клеток людей с синдромом Тимоти. Это генетическое заболевание, при котором нарушается работа сердца. Нейроны в таком органоиде отличались от тех, которые были сделаны из клеток здоровых людей, а значит модель воспроизводит особенности патологических состояний и может быть полезна при изучении патологий и тестировании лекарств. Ученые давно пытаются воспроизвести органы человека в лабораторных условиях. Кроме мозга, они создают мини-желудки, кожу и даже сердце. Исследовательский интерес — не единственное, что движет исследователями. В будущем, такие органоиды можно будет использовать для пересадки людям, в случае необходимости. Нейробиологи из США измерили у мышей активность нейронов переднедорсального ядра таламуса, участвующих\\nв контроле положения головы, и сопоставили их с движениями глаз во\\nвремя бодрствования, а потом и во сне. Оказалось, что электрическая\\nактивность и движения глаз у спящих и активных животных практически идентичны, и по\\nдвижениям глаз можно расшифровать то, как мышам снится, что они двигают головой. Статья опубликована в\\nжурнале Science.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info[10:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Финальный штрих – импортируем `pandas` и преобразуемый полученный список кортежей в датафрейм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Четвероногого робота научили стоять на воротах</td>\n",
       "      <td>Григорий Копиев</td>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>16:04</td>\n",
       "      <td>17.10.22, 2.4, Роботы и дроны</td>\n",
       "      <td>Его научили трем движениям для успешного перех...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Короткую луну-рыбу весом 2744 килограмма призн...</td>\n",
       "      <td>Сергей Коленов</td>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>17:20</td>\n",
       "      <td>17.10.22, 1.7, Зоология</td>\n",
       "      <td>Она тяжелее предыдущего рекордсмена почти на п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Четвероногого робота научили стоять на воротах</td>\n",
       "      <td>Григорий Копиев</td>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>16:04</td>\n",
       "      <td>17.10.22, 2.4, Роботы и дроны</td>\n",
       "      <td>Его научили трем движениям для успешного перех...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>На гренландских археологических памятниках наш...</td>\n",
       "      <td>Михаил Подрезов</td>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>14:50</td>\n",
       "      <td>17.10.22, 3.3, Археология</td>\n",
       "      <td>Ученые исследовали 2500 фрагментов костей живо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Плазмонный резонанс поможет определить зрелост...</td>\n",
       "      <td>Марат Хамадеев</td>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>12:43</td>\n",
       "      <td>17.10.22, 4.5, Химия, Физика</td>\n",
       "      <td>Для этого нужно запустить в напитке химическую...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0                1  \\\n",
       "0     Четвероногого робота научили стоять на воротах  Григорий Копиев   \n",
       "1  Короткую луну-рыбу весом 2744 килограмма призн...   Сергей Коленов   \n",
       "2     Четвероногого робота научили стоять на воротах  Григорий Копиев   \n",
       "3  На гренландских археологических памятниках наш...  Михаил Подрезов   \n",
       "4  Плазмонный резонанс поможет определить зрелост...   Марат Хамадеев   \n",
       "\n",
       "            2      3                              4  \\\n",
       "0  2022-10-17  16:04  17.10.22, 2.4, Роботы и дроны   \n",
       "1  2022-10-17  17:20        17.10.22, 1.7, Зоология   \n",
       "2  2022-10-17  16:04  17.10.22, 2.4, Роботы и дроны   \n",
       "3  2022-10-17  14:50      17.10.22, 3.3, Археология   \n",
       "4  2022-10-17  12:43   17.10.22, 4.5, Химия, Физика   \n",
       "\n",
       "                                                   5  \n",
       "0  Его научили трем движениям для успешного перех...  \n",
       "1  Она тяжелее предыдущего рекордсмена почти на п...  \n",
       "2  Его научили трем движениям для успешного перех...  \n",
       "3  Ученые исследовали 2500 фрагментов костей живо...  \n",
       "4  Для этого нужно запустить в напитке химическую...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(info)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не везде информация сгрузилась корректно, есть проблемы унификации, можно потом поправить это, написав функцию и применив ее через `.apply()` к соответствующим столбцам.\n",
    "\n",
    "А пока добавим содержательные названия столбцов и выгрузим датафрейм в файл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"title\", \"author\", \"date\", \"diffc\", \"rubrics\", \"text\"]\n",
    "df.to_excel(\"nplus1.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
